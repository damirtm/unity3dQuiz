<!DOCTYPE html>
<html>
<title>Unity Finland Developer Quiz</title>

<xmp theme="united" style="display:none;">
# Damir Timurshin's answers to Unity Finland - Developer Quiz

## Q1: Usually sumB would be better because of a lower count of operations but might work badly on some processor architectures. sumA probably works better with processor cache.

* I expect that sumA will have 4 times more loop jumps and comparisons than sumB. I've verified it by exploring compiler output on x86-64 architecture (https://godbolt.org/g/9QzUGt). 
* It easy to see that sumB requires 4 data registers to store sum accumulators so if the processor does have less - there will be a constant spilling/filling.
* I would expect that sumA will work better with a processor cache - cache will be warmed up faster because of switching x and y variables against a common way of walking through a two-dimensional array.
However, I'm not sure about it and going to refresh my knowledge. :-)

## Q2: API example seems to try to be RESTfull but it is not. It is also an ill-structured RPC API: works badly with proxies and difficult to use and debug.

* __GET /users__ - seems good for getting all users list with probably simple filters. For complex search, there should be a separate POST /users/search method.
* __POST /users/new__ - don't need "new" word - POST is already had semantics of a non-idempotent create (usually) operation
* __POST /users/:id/update__ - PUT method would be better and "update" word is useless in this case. It is generally a bad idea to use POST for update operations. As an example, because of non-idempotent semantics POSTed path could be remembered by proxy as processed and all duplicate requests with the same path will be rejected
* __POST /users/:id/rename__ - PUT or PATCH here would be better. I never use PATCH method - because some web servers and proxies do not support it. I would personally make this endpoint as PUT /users/:id/name.
* __POST /users/:id/update-timezone__ - looks like the previous one, just probably "update-timezone" could be replaced with "timezone".
* __DELETE /users/delete?id=:id__ - don't need "delete" word, id should be moved to path part as in previous endpoints
* Returning __HTTP/1.1 200__ for errors - is bad I think (despite that Facebook do it). In any HTTP library, it is much easier to work with HTTP status codes than extract it from a body. It is natural for proxies and browsers to work with status codes.
For POST /users/ I would use 409 Conflict status code. It says clearly that operation could not be executed and error should be shown to a user.

## Q3: Salt should be randomly generated for each user and should be longer. MD5 is probably not the best choice for password hashing.

* Fixed or short salt is vulnerable to table lookup attacks and their modifications.
* Salted MD5 is a good tradeoff between performance, disk space, and security but there are hash functions that have lower collision probability.

## Q4: Access to user's history should be read-only. getDepositHistorySum has a bad signature. Storing transactions history in the user object probably not the best idea.

* History is meant to be an immutable collection of reading operations. For example, one could copy array reference and for example, sort it with memory reusing - that could break original order and lead to unexpected behavior later.
* getDepositHistorySum should probably be a user's object own function or accept a list of deposits as a parameter. 
It can be interpreted as a violation of single responsibility principle - if users' structure will be changed - that will lead to getDepositHistorySum change as well. 
Also, getDepositHistorySum can't be reused for example to calculate the sum of deposits for a particular group of users or something else.
* For some users transaction history could be pretty big. It depends on particular context but in future, there could be some performance tradeoffs.

## Q5: Using name as a user id is bad. transferCredits should be transactional. 

* Using user's name as id is vulnerable to collisions. There is no checks that in database there is only one John or Jane.
* transferCredits should meet ACID requirements:
  - A,C: If something goes wrong we don't want for John to lose money without increasing Jane's balance and vise-versa.
  - I: John could send money to multiple users at the same time while having not enough money to do it.
  - D: Nothing here but don't use an in-memory database for users accounts! :-)

## Q6: Not sure. No parameters checks? Two methods better than one?

* Because it is javascript I can imagine that some unexpected behavior can happen. Here some possible outcomes:
 - balances could become NaN if amount missed
 - debit balance is always increased if isCredit missed
* Could amount be negative? Probably not - so check is needed
* I would recommend two separate methods here - they make the code more expressive even while more code should be written.

## Q7: Query and fetch optimizations. Indexes. Better data structures and/or schema. Caching.

* __Query optimizations__ usually the simplest way. Subqueries, unnecessary joins, unnecessary columns, wrong index usage - are common query issues.
 - Usually, database engines provide functionality for execution plan visualization.
 - Temp tables/structures could be efficient if medium delays are not a big deal - so we can construct an intermediate table for heavy queries - with there own indexes or if we need to reuse data.
 - Performance could be increased with some non-database related techniques such as pagination or parallel queries (sometimes if you have multiple replicas and want to move computation outside of the database server).
* __Indexes__ is a common way to resolve query performance - if there enough space and insert/update operations will not suffer. There could different index types and configurations for different tasks.
* Sometimes __data structures or schema__ that we chose when we first created our database works badly when the database grows, some examples are:
 - Single table for all data
 - Wrong types to store string data
 - Saving huge binary data in database
* __Caching__ is a common solution especially for read by key requests when data is rarely changed. Sometimes it can be used for search requests and sometimes even for writes - but with caution. 
There are many database engines that provide data caching and/or memory map for disk stored data. Memory map also can be provided by operating systems.
 - If we deal with caching when database size is huge - we usually cache only recent or frequently accessed data. Techniques like LRU cache can be used for example.

 #### Some solutions that also could be considered:

 * __Splitting data between multiple machines__ is a natural and proven to be a very efficient way to increase query performance. However, it is sometimes very difficult to support and their usage is very much related to context:
  - Account access could be sharded between nodes by account id. But it becomes very difficult to search users by particular properties.
  - We can partition data by date periods so recent entries could be accessed faster. But if we want to get data across long periods it can be problematic.
 * Sometimes it worth to use __different storages for data that is accessed by keys or frequently accessed (operative data) and data that is used for reporting or heavy search requests__. 
 Consistency is a usual issue in this approach but it has many advances:
  - Operative data usually could be sharded and/or cached
  - Different storage types and engines could be used: 
    - columnar databases for reporting and analytics 
    - search engines like elasticsearch to search for arbitrary properties
    - in-memory storages like Redis to cache (or even sometimes to store data)

## Q8: http://jsfiddle.net/62hw0u3v/16/

## Q9: http://jsfiddle.net/bdfu5uoe/4/
</xmp>

<script src="./strapdown.js"></script>
</html>
